{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect and compare LLMs\n",
    "\n",
    "- Connect to the grok API and choose a model\n",
    "- Connect to the Gemini API and choose a model\n",
    "- Connect to the OpenAI API and choose 4o-mini\n",
    "\n",
    "### Create a prompt and inject a little text snippet of your liking\n",
    "- The LLM should use the injected information to answer a question.\n",
    "\n",
    "### Compare the outputs\n",
    "- Use the same method for every model.\n",
    "- Do you see differences?\n",
    "\n",
    "**Tipp:** for prompt injection you can either use string concatenation or the python String formatter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google.generativeai in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google.generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google.generativeai) (2.25.0rc1)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google.generativeai) (2.169.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google.generativeai) (2.40.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google.generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google.generativeai) (2.11.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google.generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /home/codespace/.local/lib/python3.12/site-packages (from google.generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google.generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-api-core->google.generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/codespace/.local/lib/python3.12/site-packages (from google-api-core->google.generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth>=2.15.0->google.generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth>=2.15.0->google.generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth>=2.15.0->google.generativeai) (4.9.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-api-python-client->google.generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-api-python-client->google.generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-api-python-client->google.generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic->google.generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic->google.generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic->google.generativeai) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/codespace/.local/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: openai in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.78.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: groq in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.24.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from groq) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /home/codespace/.local/lib/python3.12/site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install google.generativeai\n",
    "! pip install openai\n",
    "! pip install groq\n",
    "! pip install dotenv\n",
    "import google.generativeai as genai\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Access the API key using the variable name defined in the .env file\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\"env/.env\")  # ← wichtig!\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001 - ['generateMessage', 'countMessageTokens']\n",
      "models/text-bison-001 - ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "models/embedding-gecko-001 - ['embedText', 'countTextTokens']\n",
      "models/gemini-1.0-pro-vision-latest - ['generateContent', 'countTokens']\n",
      "models/gemini-pro-vision - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-latest - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-001 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro-002 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-latest - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-001 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-001-tuning - ['generateContent', 'countTokens', 'createTunedModel']\n",
      "models/gemini-1.5-flash - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-002 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-8b - ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-001 - ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-latest - ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-exp-0827 - ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-exp-0924 - ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-pro-exp-03-25 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.5-pro-preview-03-25 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.5-flash-preview-04-17 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.5-flash-preview-04-17-thinking - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.5-pro-preview-05-06 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-exp - ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-001 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-lite-001 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-lite - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-lite-preview - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-pro-exp - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-pro-exp-02-05 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-exp-1206 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-thinking-exp - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 - ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/learnlm-2.0-flash-experimental - ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it - ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it - ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it - ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it - ['generateContent', 'countTokens']\n",
      "models/embedding-001 - ['embedContent']\n",
      "models/text-embedding-004 - ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 - ['embedContent', 'countTextTokens']\n",
      "models/gemini-embedding-exp - ['embedContent', 'countTextTokens']\n",
      "models/aqa - ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 - ['predict']\n",
      "models/veo-2.0-generate-001 - ['predictLongRunning']\n",
      "models/gemini-2.0-flash-live-001 - ['bidiGenerateContent', 'countTokens']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "models = genai.list_models()\n",
    "for model in models:\n",
    "    print(model.name, \"-\", model.supported_generation_methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/quickstart?hl=de&lang=python\n",
    "examples: https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/System_instructions.ipynb?hl=de#scrollTo=WxiIfsbA0WdH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\"env/.env\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "model = genai.GenerativeModel(\"models/gemini-1.5-pro\")  # ← wichtig: vollständiger Name\n",
    "response = model.generate_content(\"What is Retrieval-Augmented Generation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-Augmented Generation (RAG) is a technique in natural language processing (NLP) that combines the strengths of information retrieval (IR) systems with the generative capabilities of large language models (LLMs).  Instead of relying solely on the knowledge encoded within the LLM's parameters, RAG allows the model to access and process external information relevant to a given prompt, leading to more accurate, up-to-date, and comprehensive responses.\n",
      "\n",
      "Here's a breakdown of how it works:\n",
      "\n",
      "1. **Retrieval:** Given a user prompt, a relevant document or set of documents is retrieved from an external knowledge base. This knowledge base can be anything from a specific dataset, a collection of web pages, or even a codebase.  The retrieval process typically involves techniques like keyword search, semantic search, or embedding-based similarity matching.\n",
      "\n",
      "2. **Augmentation:**  The retrieved document(s) are then used to augment the prompt provided to the LLM. This can be done in several ways, such as:\n",
      "    * **Prepending retrieved documents to the prompt:** The LLM receives the retrieved information before the user's query, allowing it to consider the context before generating a response.\n",
      "    * **Inserting relevant excerpts within the prompt:** Specific parts of the retrieved documents most relevant to the query are inserted into the prompt.\n",
      "    * **Providing retrieved documents as separate context:** The retrieved documents are passed alongside the prompt, often with clear markers to distinguish between user input and retrieved context.\n",
      "\n",
      "3. **Generation:**  The LLM uses both the original prompt and the retrieved information to generate the output.  By grounding its response in the provided context, the LLM is less likely to hallucinate or generate factually incorrect information.\n",
      "\n",
      "**Benefits of RAG:**\n",
      "\n",
      "* **Improved Accuracy:** Access to external information allows LLMs to produce more accurate and factually grounded responses.\n",
      "* **Up-to-date Information:**  RAG enables LLMs to access the latest information, overcoming the limitations of their static training data.\n",
      "* **Reduced Hallucinations:** Providing relevant context minimizes the tendency of LLMs to generate fabricated or irrelevant information.\n",
      "* **Explainability and Traceability:**  By referencing the retrieved documents, RAG systems offer greater transparency into how the LLM arrived at its conclusions.\n",
      "* **Adaptability to Specific Domains:**  RAG can be easily adapted to specific domains by using specialized knowledge bases.\n",
      "\n",
      "\n",
      "**Examples of RAG Applications:**\n",
      "\n",
      "* **Question answering systems:** Providing accurate answers to user queries based on a specific knowledge base.\n",
      "* **Chatbots:** Enabling more informative and context-aware conversations.\n",
      "* **Text summarization:** Generating summaries that incorporate information from multiple sources.\n",
      "* **Code generation:** Assisting developers by retrieving relevant code snippets and documentation.\n",
      "\n",
      "**Challenges of RAG:**\n",
      "\n",
      "* **Retrieval Effectiveness:**  The quality of the retrieved documents directly impacts the quality of the generated output.  Improving retrieval mechanisms is crucial.\n",
      "* **Context Window Limitations:**  LLMs have limited context windows, restricting the amount of retrieved information they can process simultaneously.\n",
      "* **Computational Cost:** Retrieving and processing external information can be computationally expensive.\n",
      "* **Handling Noisy or Irrelevant Data:** The retrieved information may contain noisy or irrelevant data, which can negatively affect the LLM's performance.\n",
      "\n",
      "\n",
      "Despite these challenges, RAG represents a significant advancement in NLP, bridging the gap between information retrieval and generation to create more powerful and knowledgeable language models.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groq\n",
    "https://console.groq.com/docs/quickstart\n",
    "\n",
    "goal: llama-3.3-70b-versatile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(llm.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
